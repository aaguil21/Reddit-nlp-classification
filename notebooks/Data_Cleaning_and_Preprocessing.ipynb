{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "--------\n",
    "\n",
    "This notebook contains:\n",
    "* [Preprocessing](#Preprocessing)\n",
    "* [Word Processing](#Word-Processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import re\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "      <th>neu_score</th>\n",
       "      <th>compound_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1319b5m</td>\n",
       "      <td>25F Rash on back of knee</td>\n",
       "      <td>25F, I've had a rash on the back of my right k...</td>\n",
       "      <td>AskDocs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.817</td>\n",
       "      <td>-0.9559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1319avc</td>\n",
       "      <td>idk if me or my gf have hpv or smthing why is ...</td>\n",
       "      <td>im a 20 year old girl (with a peepee) and i ha...</td>\n",
       "      <td>AskDocs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.805</td>\n",
       "      <td>-0.9865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13199bu</td>\n",
       "      <td>bruise after blood test?</td>\n",
       "      <td>20f uk \\n\\njust concerned cause it’s been over...</td>\n",
       "      <td>AskDocs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.847</td>\n",
       "      <td>-0.8848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13199a7</td>\n",
       "      <td>Heart palpitations while pushing during a bowe...</td>\n",
       "      <td>Hi i (19m 186cm 89kg) have been having bad day...</td>\n",
       "      <td>AskDocs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.891</td>\n",
       "      <td>-0.3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13197g1</td>\n",
       "      <td>Left side of my body between rib cage and hip ...</td>\n",
       "      <td>So as the title says, I [22M] have been feelin...</td>\n",
       "      <td>AskDocs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.813</td>\n",
       "      <td>-0.0123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                              title  \\\n",
       "0  1319b5m                           25F Rash on back of knee   \n",
       "1  1319avc  idk if me or my gf have hpv or smthing why is ...   \n",
       "2  13199bu                           bruise after blood test?   \n",
       "3  13199a7  Heart palpitations while pushing during a bowe...   \n",
       "4  13197g1  Left side of my body between rib cage and hip ...   \n",
       "\n",
       "                                           self_text subreddit comment  \\\n",
       "0  25F, I've had a rash on the back of my right k...   AskDocs     NaN   \n",
       "1  im a 20 year old girl (with a peepee) and i ha...   AskDocs     NaN   \n",
       "2  20f uk \\n\\njust concerned cause it’s been over...   AskDocs     NaN   \n",
       "3  Hi i (19m 186cm 89kg) have been having bad day...   AskDocs     NaN   \n",
       "4  So as the title says, I [22M] have been feelin...   AskDocs     NaN   \n",
       "\n",
       "  comment_id  pos_score  neg_score  neu_score  compound_score  \n",
       "0        NaN      0.033      0.150      0.817         -0.9559  \n",
       "1        NaN      0.016      0.179      0.805         -0.9865  \n",
       "2        NaN      0.051      0.102      0.847         -0.8848  \n",
       "3        NaN      0.039      0.070      0.891         -0.3182  \n",
       "4        NaN      0.100      0.086      0.813         -0.0123  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data set of merged data and sentiment analysis\n",
    "df = pd.read_csv('../data/full_subreddits_w_sentiment.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the preprocessing portion, I will conduct an analysis of the text for the `self_text` and `title` features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to check if there is any use of emojis in the dataset, this will have to be removed as to remove any unwanted characters in the vectorization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoji_finder(text:list):\n",
    "    \"\"\"\n",
    "    Counts the number of strings that have an emoji in a list of strings\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for i in text:\n",
    "        if not (i != i):\n",
    "            if emoji.emoji_count(i) > 0:\n",
    "                count +=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries with emojis in Title: 10\n",
      "Number of entries with emojis in Self Text: 137\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of entries with emojis in Title: {emoji_finder(df[\"title\"])}')\n",
    "print(f'Number of entries with emojis in Self Text: {emoji_finder(df[\"self_text\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of emojis used in the titles and selt_text, so I will add a feature in the preprocesser to remove the emojis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_finder(text:list):\n",
    "    \"\"\"\n",
    "    Counts the number of strings that have a url in a list of strings\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for i in text:\n",
    "        if not (i != i):\n",
    "            if re.findall(r\"\\S*https?:\\S*\", i):\n",
    "                count +=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries with urls in Title: 0\n",
      "Number of entries with urls in Self Text: 1630\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of entries with urls in Title: {url_finder(df[\"title\"])}')\n",
    "print(f'Number of entries with urls in Self Text: {url_finder(df[\"self_text\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Urls are seen frequently in the `selt_text` of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reddit_talk (text:list):\n",
    "    \"\"\"\n",
    "    Counts the number of strings that have an instance of reddit lingo in a list of strings\n",
    "    \"\"\"\n",
    "    scount = 0\n",
    "    count = 0\n",
    "    for i in text:\n",
    "        if not (i != i):\n",
    "            if re.findall('[MF][0-9][0-9]', i):\n",
    "                count +=1\n",
    "            if re.findall('/[a-z]\\S', i):\n",
    "                count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries with urls in Title: 363\n",
      "Number of entries with urls in Self Text: 3215\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of entries with urls in Title: {reddit_talk(df[\"title\"])}')\n",
    "print(f'Number of entries with urls in Self Text: {reddit_talk(df[\"self_text\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_preprocessor(text):\n",
    "    \"\"\"\n",
    "    Custom preporcessor to be used for TfidfVectorizer. Removal and change of word features based on preporcessing such as emoji removal, \n",
    "    url removal, and reddit lingo adaption. \n",
    "    \"\"\"\n",
    "    text  = text.lower()\n",
    "    text = re.sub('\\\\n','', text)\n",
    "    text = re.sub('\\[removed\\]','', text)\n",
    "    text = emoji.replace_emoji(text, replace=\"\")\n",
    "    text = re.sub(r\"\\S*https?:\\S*\", \"\", text)\n",
    "    text = re.sub('[MF][0-9][0-9]', '', text)\n",
    "    text = re.sub('/[a-z]\\S', ' or ', text)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = TfidfVectorizer(\n",
    "    stop_words=stopwords.words('english'),\n",
    "    ngram_range=(2, 5),\n",
    "    max_df= 0.3,\n",
    "    min_df= 5,\n",
    "    preprocessor=my_preprocessor,\n",
    "    max_features = 250\n",
    "    )\n",
    "\n",
    "df_t  = cv.fit_transform(df['self_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tt = pd.DataFrame(df_t.todense(), columns = cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "photo relevant         20.190235\n",
       "coming back            20.183432\n",
       "primary care           20.120734\n",
       "get worse              20.072575\n",
       "around time            20.020446\n",
       "go see                 19.963300\n",
       "30 minutes             19.021204\n",
       "swollen lymph          18.679661\n",
       "left ear               18.457302\n",
       "weeks later            18.431558\n",
       "right ear              17.969385\n",
       "started feel           17.956120\n",
       "feel better            17.705412\n",
       "back negative          17.501683\n",
       "blood work done        17.243456\n",
       "went urgent care       16.871956\n",
       "went urgent            16.871956\n",
       "high blood             15.640944\n",
       "high blood pressure    15.271110\n",
       "reference range        10.386774\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tt.sum().sort_values(ascending=False).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1 = TfidfVectorizer(\n",
    "    stop_words=stopwords.words('english'),\n",
    "    ngram_range=(1, 1),\n",
    "    max_df= 0.25,\n",
    "    min_df= 10,\n",
    "    preprocessor=my_preprocessor,\n",
    "    max_features = 250\n",
    "    )\n",
    "\n",
    "df_t1  = cv1.fit_transform(df['self_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t1 = pd.DataFrame(df_t1.todense(), columns = cv1.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pain         321.618365\n",
       "one          268.742667\n",
       "back         248.973951\n",
       "know         247.249632\n",
       "could        246.637184\n",
       "house        237.676566\n",
       "time         237.082537\n",
       "right        231.272741\n",
       "water        222.764809\n",
       "years        214.343511\n",
       "need         212.773866\n",
       "something    209.640740\n",
       "really       207.819965\n",
       "days         205.977448\n",
       "since        205.583923\n",
       "day          204.064163\n",
       "want         203.797690\n",
       "ago          201.728339\n",
       "normal       199.962246\n",
       "go           199.649868\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t1.sum().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
